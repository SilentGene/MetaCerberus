=====================================================
Start Time  : Wed Aug  9 12:09:27 EDT 2023
Submit Dir  : /projects/raw_lab/jobs/metacerberus
Job ID/Name : 5428284 / Metacerberus_chunker-1mb
Node List   : str-c[74-78]
Num Tasks   : 5 total [5 nodes @ 36 CPUs/node]
======================================================

======================================================
Running Metacerberus_chunker-1mb On VIRAL_METAGENOME/genomes/QGNH01.1.fna
======================================================
Initializing Ray on 5 Nodes
IP Head: 192.168.170.74:6379
Starting HEAD at str-c74
Starting WORKER 1 at str-c75
Starting WORKER 2 at str-c76
2023-08-09 12:09:40,342	INFO scripts.py:894 -- [37mLocal node IP[39m: [1m192.168.170.76[22m
2023-08-09 12:09:40,684	SUCC scripts.py:906 -- [32m--------------------[39m
2023-08-09 12:09:40,684	SUCC scripts.py:907 -- [32mRay runtime started.[39m
2023-08-09 12:09:40,684	SUCC scripts.py:908 -- [32m--------------------[39m
2023-08-09 12:09:40,684	INFO scripts.py:910 -- To terminate the Ray runtime, run
2023-08-09 12:09:40,685	INFO scripts.py:911 -- [1m  ray stop[22m
2023-08-09 12:09:40,685	INFO scripts.py:919 -- [36m[1m--block[22m[39m
2023-08-09 12:09:40,685	INFO scripts.py:920 -- This command will now block forever until terminated by a signal.
2023-08-09 12:09:40,685	INFO scripts.py:923 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
[2023-08-09 12:09:42,186 W 1544436 1544436] global_state_accessor.cc:389: Some processes that the driver needs to connect to have not registered with GCS, so retrying. Have you run 'ray start' on this node?
[2023-08-09 12:09:42,534 W 843137 843137] global_state_accessor.cc:389: Some processes that the driver needs to connect to have not registered with GCS, so retrying. Have you run 'ray start' on this node?
2023-08-09 12:09:39,124	INFO scripts.py:894 -- [37mLocal node IP[39m: [1m192.168.170.75[22m
2023-08-09 12:09:43,188	SUCC scripts.py:906 -- [32m--------------------[39m
2023-08-09 12:09:43,188	SUCC scripts.py:907 -- [32mRay runtime started.[39m
2023-08-09 12:09:43,188	SUCC scripts.py:908 -- [32m--------------------[39m
2023-08-09 12:09:43,188	INFO scripts.py:910 -- To terminate the Ray runtime, run
2023-08-09 12:09:43,188	INFO scripts.py:911 -- [1m  ray stop[22m
2023-08-09 12:09:43,188	INFO scripts.py:919 -- [36m[1m--block[22m[39m
2023-08-09 12:09:43,188	INFO scripts.py:920 -- This command will now block forever until terminated by a signal.
2023-08-09 12:09:43,188	INFO scripts.py:923 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
2023-08-09 12:09:39,124	INFO usage_lib.py:408 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2023-08-09 12:09:39,124	INFO scripts.py:712 -- [37mLocal node IP[39m: [1m192.168.170.74[22m
2023-08-09 12:09:43,536	SUCC scripts.py:749 -- [32m--------------------[39m
2023-08-09 12:09:43,536	SUCC scripts.py:750 -- [32mRay runtime started.[39m
2023-08-09 12:09:43,536	SUCC scripts.py:751 -- [32m--------------------[39m
2023-08-09 12:09:43,536	INFO scripts.py:753 -- [36mNext steps[39m
2023-08-09 12:09:43,536	INFO scripts.py:756 -- To add another node to this Ray cluster, run
2023-08-09 12:09:43,536	INFO scripts.py:759 -- [1m  ray start --address='192.168.170.74:6379'[22m
2023-08-09 12:09:43,536	INFO scripts.py:768 -- To connect to this Ray cluster:
2023-08-09 12:09:43,536	INFO scripts.py:770 -- [35mimport[39m[26m ray
2023-08-09 12:09:43,536	INFO scripts.py:771 -- ray[35m.[39m[26minit(_node_ip_address[35m=[39m[26m[33m'192.168.170.74'[39m[26m)
2023-08-09 12:09:43,536	INFO scripts.py:783 -- To submit a Ray job using the Ray Jobs CLI:
2023-08-09 12:09:43,536	INFO scripts.py:784 -- [1m  RAY_ADDRESS='http://127.0.0.1:8265' ray job submit --working-dir . -- python my_script.py[22m
2023-08-09 12:09:43,536	INFO scripts.py:793 -- See https://docs.ray.io/en/latest/cluster/running-applications/job-submission/index.html 
2023-08-09 12:09:43,536	INFO scripts.py:797 -- for more information on submitting Ray jobs to the Ray cluster.
2023-08-09 12:09:43,537	INFO scripts.py:802 -- To terminate the Ray runtime, run
2023-08-09 12:09:43,537	INFO scripts.py:803 -- [1m  ray stop[22m
2023-08-09 12:09:43,537	INFO scripts.py:806 -- To view the status of the cluster, use
2023-08-09 12:09:43,537	INFO scripts.py:807 --   [1mray status[22m[26m
2023-08-09 12:09:43,537	INFO scripts.py:811 -- To monitor and debug Ray, view the dashboard at 
2023-08-09 12:09:43,537	INFO scripts.py:812 --   [1m127.0.0.1:8265[22m[26m
2023-08-09 12:09:43,537	INFO scripts.py:819 -- [4mIf connection to the dashboard fails, check your firewall settings and network configuration.[24m
2023-08-09 12:09:43,537	INFO scripts.py:919 -- [36m[1m--block[22m[39m
2023-08-09 12:09:43,538	INFO scripts.py:920 -- This command will now block forever until terminated by a signal.
2023-08-09 12:09:43,538	INFO scripts.py:923 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
Starting WORKER 3 at str-c77
[2023-08-09 12:09:44,971 I 3855603 3855603] global_state_accessor.cc:356: This node has an IP address of 192.168.170.77, but we cannot find a local Raylet with the same address. This can happen when you connect to the Ray cluster with a different IP address or when connecting to a container.
2023-08-09 12:09:44,918	INFO scripts.py:894 -- [37mLocal node IP[39m: [1m192.168.170.77[22m
2023-08-09 12:09:44,972	SUCC scripts.py:906 -- [32m--------------------[39m
2023-08-09 12:09:44,972	SUCC scripts.py:907 -- [32mRay runtime started.[39m
2023-08-09 12:09:44,972	SUCC scripts.py:908 -- [32m--------------------[39m
2023-08-09 12:09:44,972	INFO scripts.py:910 -- To terminate the Ray runtime, run
2023-08-09 12:09:44,972	INFO scripts.py:911 -- [1m  ray stop[22m
2023-08-09 12:09:44,972	INFO scripts.py:919 -- [36m[1m--block[22m[39m
2023-08-09 12:09:44,972	INFO scripts.py:920 -- This command will now block forever until terminated by a signal.
2023-08-09 12:09:44,972	INFO scripts.py:923 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
Starting WORKER 4 at str-c78
[2023-08-09 12:09:50,202 I 1787049 1787049] global_state_accessor.cc:356: This node has an IP address of 192.168.170.78, but we cannot find a local Raylet with the same address. This can happen when you connect to the Ray cluster with a different IP address or when connecting to a container.
2023-08-09 12:09:50,075	INFO scripts.py:894 -- [37mLocal node IP[39m: [1m192.168.170.78[22m
2023-08-09 12:09:50,203	SUCC scripts.py:906 -- [32m--------------------[39m
2023-08-09 12:09:50,203	SUCC scripts.py:907 -- [32mRay runtime started.[39m
2023-08-09 12:09:50,203	SUCC scripts.py:908 -- [32m--------------------[39m
2023-08-09 12:09:50,203	INFO scripts.py:910 -- To terminate the Ray runtime, run
2023-08-09 12:09:50,203	INFO scripts.py:911 -- [1m  ray stop[22m
2023-08-09 12:09:50,203	INFO scripts.py:919 -- [36m[1m--block[22m[39m
2023-08-09 12:09:50,203	INFO scripts.py:920 -- This command will now block forever until terminated by a signal.
2023-08-09 12:09:50,203	INFO scripts.py:923 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.
HMM: 'KOFam_all'
HMM: 'COG'
HMM: 'VOG'
HMM: 'PHROG'
HMM: 'CAZy'

Starting MetaCerberus Pipeline

Checking for external dependencies:
fastqc               /users/jlfiguer/.conda/envs/metacerberus-dev/bin/fastqc
flash2               /users/jlfiguer/.conda/envs/metacerberus-dev/bin/flash2
fastp                /users/jlfiguer/.conda/envs/metacerberus-dev/bin/fastp
porechop             /users/jlfiguer/.conda/envs/metacerberus-dev/bin/porechop
bbduk.sh             /users/jlfiguer/.conda/envs/metacerberus-dev/bin/bbduk.sh
FragGeneScanRs       /users/jlfiguer/.conda/envs/metacerberus-dev/lib/python3.10/site-packages/meta_cerberus/FGS/FragGeneScanRs
prodigal             /users/jlfiguer/.conda/envs/metacerberus-dev/bin/prodigal
hmmsearch            /users/jlfiguer/.conda/envs/metacerberus-dev/bin/hmmsearch
countAssembly.py     /users/jlfiguer/.conda/envs/metacerberus-dev/bin/countAssembly.py
Initializing RAY
2023-08-09 12:10:15,110	INFO worker.py:1452 -- Connecting to existing Ray cluster at address: 192.168.170.74:6379...
2023-08-09 12:10:15,175	INFO worker.py:1627 -- Connected to Ray cluster. View the dashboard at [1m[32m127.0.0.1:8265 [39m[22m
Started RAY on cluster
Running RAY on 5 node(s)
Using 36 CPUs per node

STEP 1: Loading sequence files:
Processing 0 fastq sequences
Processing 1 fasta sequences
Processing 0 protein Sequences

STEP 5a: Removing N's from contig files

STEP 6: Metaome Stats


STEP 7: ORF Finder


STEP 8: HMMER Search


STEP 10: Creating Reports
Saving Statistics
Traceback (most recent call last):
  File "/users/jlfiguer/.conda/envs/metacerberus-dev/bin/metacerberus.py", line 693, in <module>
    sys.exit(main())
  File "/users/jlfiguer/.conda/envs/metacerberus-dev/bin/metacerberus.py", line 581, in main
    metacerberus_report.write_Stats(report_path, readStats, protStats, NStats, config)
  File "/users/jlfiguer/.conda/envs/metacerberus-dev/lib/python3.10/site-packages/meta_cerberus/metacerberus_report.py", line 134, in write_Stats
    dictStats[key]["Contigs w/ N-repeats:"] = len(value)
KeyError: 'prodigal_QGNH01.1'
Command exited with non-zero status 1
9.54user 4.10system 12:30.89elapsed 1%CPU (0avgtext+0avgdata 219160maxresident)k
387472inputs+621928outputs (638major+70065minor)pagefaults 0swaps

======================================================
End Time   : Wed Aug  9 12:22:24 EDT 2023
Run Time   : 777 seconds
======================================================

Disk Used 122776 results/Metacerberus_chunker-1mb/VIRAL_METAGENOME/genomes/QGNH01.1
